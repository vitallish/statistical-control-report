---
title: "Statistical Process Control in Healthcare"
subtitle: "Final Project - Masters of Arts - Biostatistics"
author: "Vitaly Druker"
date: "Spring 2018"
output: bookdown::pdf_document2
bibliography: ["bibliography.bib"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
# Data Cleaning/Manipulation
library(dplyr)
library(tidyr)
library(magrittr)
library(broom)

# Statistical Calculations
library(qcc)

# Data Presentation
library(ggplot2)
library(pander)

# Other Utilities
library(lubridate)
library(fs)
library(purrr)

files_to_src <- dir_ls(path ='src_files', type = "file", glob = "*.R")
purrr::walk(files_to_src, source)

ggplot2::theme_set(
  theme_minimal() %+replace%
    theme(
      legend.position = "bottom",
      panel.grid.minor = element_blank(),
      axis.ticks = element_line(colour = "grey20")
    )
)
```

# Introduction

## General Statistical Control 

Statistical process control has been used in the manufacturing industries since the 1920s. They were popularised by Walter A. Shewhart at Bell Labs [@shewhart-1931]. Statisical process control (SPC) attempts to answer a relatively simple question: is a process changing over time?

Specifically, SPC defines two types of variation: common cause (called chance by Shewhart) and special cause (assignable) variation. Common cause variation can be viewed as process variation that is predictable, stable and (sometimes) unavoidable. This is variation that can be see as being inherent to the process itself. For example, a dart player will not hit a bullseye every time. The dart play can lower their variation, but it's unlikely that it will become entirely absent.

On the other hand, special cause variation is variation in either the measurement itself or variation in the variance of the measurement that is outside. This is the variation that SPC tries to identify because it needs to be investigated as a possible issue in a process that was thought to be stable before. In continuing with the dart player example from before, there may be cause for concern if the player begins to consistently miss to left of the bulls eye. The dart player may be fatigued and needs to retire before hitting one of their friends. On the other hand, a dart player may have had a high variance in hitting the bullseye and has started to cluster more towards the center of the bulls eye. Perhaps a fellow player demonstrated the correct way to hold a dart and the dart players percision improved. This could also be noted as special cause variation. Special cause variation does not need to imply a negative outcome - simply that there is a _change_ in the process that may be attributed to an event.

The reader may begin to formulate some of the balances that need to be struck in these analyses:

When do we decide that the difference in accuracy is consistently significantly different than before? It can be helpful to imagine an extreme situation. The first dart thrown by the player hits the center of the board. The next hits the wall. Was the second throw 'out of control'? It'd be hard to make that decision. However, if 100/1000 first throws are bullseyes and the next 200 are not, the problem becomes more difficult.

## Expansion of the Methodology 

An additional problem becomes apparent when the field of application is considered. Shewhart developed his theory to be used in a manufacturing setting where measurements could be done fairly cheaply, repeatedly and in a relatively controlled setting. As more industries were able to set up repeatable measurements with advances in technology, SPC has been applied to software engineering [@UpgradeAppraisalRequirements2006], financial services [@BinJumah2012] and food control [@DORA2013607]. The strong adoption of SPC by Six Sigma methodology has not hindered this growth (@sixsigma).

Another field that has not been immune to influence of SPC is healthcare [@lunderberg2007]. Statistical process control can be applied to everything from patient waiting times to clinical outcomes. However, simple classical SPC is ill equiped to deal with the wide variablity of the healthcare field (and some of the other fields mentioned above [@Raczynski]). Healthcare data can also suffer from missingness, measurement error and issues in consistent collection. All of these concept lead to wide variablity and unsatisfying results.

## Report Contents

This report will begin with an in-depth review of statistical process control methodology, specifically as it applies to healthcare data. Some drawbacks in the methods will be exposed using simulated data. Finally, two different versions of SPC beyond the classical charts will be explored.


\newpage

# Data Simulation 

## Knobs 

1. Link Function
    - Logit
    - Identity
    - ln

2. Change 
    - How long until Change starts?
    - Magnitude of Change?
    - Length of Change?
    - Change Function (Linear vs. Quadratic)


## Tests

- Detection Rate
- Run Length (RL) (Median and 50% quantile)
- False Positive Rate



```{r}
generateData <- function(data_sparcity = 0.1,
                         observations_per_day = 5,
                         process_start = .4,
                         process_change = .2,
                         stat_start  = 0, # c(-3,0,3)
                         stat_change = 1, #  c(0, .1, 1, 10)
                         stat_change_type = "linear", # c("linear", "quadratic")
                         data_type  = "measurement", #c("measurement", "rate", "count"),
                         date_floor = "quarter",
                         sd_perc = 0.1,  #c(.1, .5, 1),
                         covariates,
                         seed_num = NA, 
                         ...) {
  if (!is.na(seed_num))
    set.seed(seed_num)
  
  
  # global options
  start_date <- ymd('2016-01-01')
  end_date <- ymd('2017-12-31')
  date_range <- seq(start_date, end_date, by = 1) 
  total_dates <- length(date_range)
  
  dates_to_sample <- sample(size = round(data_sparcity * total_dates), 
                          x = date_range, 
                          replace = FALSE)
  
  total_observations <- round(data_sparcity * total_dates * observations_per_day)
  final_dates <- sample(x = dates_to_sample, 
                        size = total_observations, 
                        replace = TRUE)
  
  if(!missingArg(covariates)){
    d <- covariates %>%
      sample_n(total_observations,
      replace = TRUE) %>%
      mutate(dt = final_dates) %>%
      select(dt, everything())
  }else{
    d <- data.frame(dt = final_dates)
  }
  
  # Change process definition
  if(!between(process_start, .1, .9)) stop("Please provide valid process_start")
  if(!between(process_change, 0, 1-process_start)) stop("Please provide valid process_change")
  
  process_end_change <- process_start + process_change
  process_dates <- quantile(as.numeric(date_range),
                            c(process_start, process_end_change))
  
  process_length <- process_dates[2]-process_dates[1]
  
  
  d <- d %>% 
    mutate(dt_int = as.numeric(dt)) %>% 
    mutate(dt_group = floor_date(dt, unit = date_floor)) %>% 
    mutate(in_process = between(dt_int, process_dates[1], process_dates[2])) %>% 
    mutate(baseline = stat_start)
  
  
  # Process Change Functions 
  if (stat_change_type == "linear") {
    d <- d %>%
      mutate(
        true_stat = case_when(
          dt_int < process_dates[1] ~ baseline,
          in_process ~ baseline + stat_change * (dt_int - process_dates[1]) /
            process_length,
          dt > process_dates[2] ~ baseline + stat_change
        )
      )
  } else if (stat_change_type == "quadratic") {
    d <- d %>%
      mutate(
        true_stat =
          case_when(
            dt_int < process_dates[1] ~ baseline,
            in_process ~ baseline - (dt_int - process_dates[1]) * (dt_int -
                                                                     process_dates[2]) / (process_length ^ 2) * stat_change,
            dt_int > process_dates[2] ~ baseline
          )
      )
    
    
  }
  
  # Apply Link Functions and Create Data
  if(data_type == "measurement"){
    d <- d %>% 
      mutate(data_samp = rnorm(n = nrow(.), mean = true_stat, sd = stat_change*sd_perc))
  }else if(data_type == "rate"){
    d <- d %>% 
      mutate(true_stat = boot::inv.logit(true_stat),
             data_samp = rbinom(n = nrow(.), size = 1, prob = true_stat))
  }
  
  d <- d %>% 
    arrange(dt)
  
  attr(d, "data_type") <- data_type
  attr(d, "stat_change_type") <- stat_change_type
  
  d
  
}

# load("ref_data/sick_data.Rdata")
```


```{r}
createQCC <- function(d, cutoff = NULL){
  data_type <- attr(d, "data_type")
  type <- case_when(
    data_type == "rate" ~ "p",
    data_type == "measurement" ~ "xbar"
  )
  
  if(is.null(cutoff)){
    out <- try(qcc.formula(data_samp ~ dt_group, data = d, type = type), silent = T)
  }else{
    out <- try(qcc.formula(data_samp ~ dt_group, data = d, cutoff = cutoff, type = type), silent = T)
  }
  
  if(inherits(out, "try-error")) out <- NA
  
  out
}

evalQCC  <- function(d, qcc_obj, 
                     invalid_runs = c("Violating Run", "Beyond Limits"), ...){
  if(is.na(qcc_obj)[[1]]) return(data.frame(false_positive = NA,
                                            true_positive = NA,
                                            arl = NA))
  true_stats <- d %>% 
    group_by(dt_group) %>% 
    summarise(true_stat = mean(true_stat),
              in_process = any(in_process)) %>% 
    mutate(diff_stat = true_stat != first(true_stat))
  
  
  calc_df <-  augment.qcc(qcc_obj, gr_func = as.Date) %>% 
    rename(dt_group = group) %>% 
    mutate(dt_group = dt_group + days(1)) %>% 
    left_join(true_stats, by = "dt_group") 
  
  
  emp_process_start <- calc_df %>% 
    filter(diff_stat) %>% 
    top_n(-1, dt_group) %>% 
    pull(dt_group)
  
  first_detect <- calc_df %>% 
    filter(diff_stat, violations %in% invalid_runs) %>% 
    top_n(-1, dt_group) %>% 
    pull(dt_group)
  
  arl <- ifelse(length(first_detect) == 1, 
                as.numeric(first_detect - emp_process_start, unit = "days"), Inf)

  calc_df %>% 
    summarise(
      false_positive = any(!diff_stat & violations %in% invalid_runs),
      true_positive = any(diff_stat & violations %in% invalid_runs),
      arl = arl
    )
}

```


```{r}


param_grid <- expand.grid(
  data_sparcity = c(.1, .5, .8),
  observations_per_day = c(1, 5, 10),
  process_start = c(.2, .4, .8),
  process_change = c(.1, .3, .5),
  stat_start  = c(-3,0,3),
  stat_change = c(0, .1, 1, 10),
  sd_perc = c(NA, .1, .3, .8),
  stat_change_type = c("linear", "quadratic"),
  data_type  =c("measurement", "rate"),#, "count"),
  date_floor = c("week","month", "quarter"),
  stringsAsFactors = FALSE
) %>% 
  as_tibble()

param_grid <- param_grid %>% 
  filter(process_change + process_start < .9) %>% 
  filter((data_type == "measurement" & !is.na(sd_perc)) |
           (data_type %in% c("rate", "count") & is.na(sd_perc))) 
```



```{r}

set.seed(2)
temp <- param_grid %>% 
  sample_n(100) %>% 
  mutate(data = pmap(., generateData)) %>% 
  mutate(booted_data = map(data, bootstrap, m = 5))
  mutate(qcc_obj = map(data, ~createQCC(.x))) %>% 
  mutate(qcc_eval = map2(data, qcc_obj, ~evalQCC(.x, .y))) %>% 
  select(-data, -qcc_obj) %>% 
  unnest()

temp %>% 
  ggplot(aes(x = stat_change, y = arl)) + geom_point() + facet_wrap(~data_type)

# class(temp$qcc_obj[[1]])
```



\newpage

# Classic Statistical Process Control

## Overview 
The main process for statistical control involves a two stage process:
1. Estimate parameters that describe the 'center' and 'spread' of the process being measured.
2. Apply these parameters to observed data to detect any change.

The recommended method for this is to estimate the paramaters from an initial stage (Phase I) and then apply them to new data (Phase 2). This process is analgaous to the 'test/train' methodology found in machine learning. It's still possible to estimate these parameters from the same data that is being evaluated, as will be shown below.

As the analyst works through the quality control charting process a number of decisions need to be made. In this instance we can assume that the central/spread parameters will be estimated from the data and not predefined.

1. How will the data be grouped (e.g. ill the analysis be grouped be weeks or by months)?
2. How will estimates of central tendancy and spread be calculated. This is often tied to the distribution assumed for the process.
3. What are the rules that indicate a process is 'out of control'. This can be seen as finding the balance between type I and type II error.

## Tools Used

The \code{qcc}[@R-qcc] is used to perform all statistical charting control in this section.

## Continous Measurment Analysis 

We begin by simulating data for patient wait times

```{r}

```




# Next Steps

Other "Knobs"

1. Autocorrelation Degree
2. Cyclical Comonents
    3.1 Amplitude
    3.2 Frequency 


\newpage
# Bibliography




